{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04243f65",
   "metadata": {},
   "source": [
    "# Module 7: Learning to Rank\n",
    "\n",
    "This notebook contains 3 learning to rank models and associated metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0057c8",
   "metadata": {},
   "source": [
    "## Import and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff2178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "DATA_DIR = \"data/ml-100k/\"\n",
    "\n",
    "ratings = pd.read_csv(DATA_DIR + 'u.data',\n",
    "                      sep='\\t',\n",
    "                      names=['user', 'item', 'rating', 'timestamp'])\n",
    "\n",
    "users = pd.read_csv(DATA_DIR + 'u.user', \n",
    "                    sep='|',\n",
    "                    names=['user', 'age', 'gender', 'occupation', 'zip_code'])\n",
    "\n",
    "movies = pd.read_csv(DATA_DIR + 'u.item', \n",
    "                     sep='|', \n",
    "                     encoding='latin-1', \n",
    "                     header = None,\n",
    "                     names = ['item', 'title', 'release_date', 'video_release_date', 'IMDb_URL'] +\n",
    "                           [f'genre_{i}' for i in range(19)])\n",
    "\n",
    "\n",
    "ratings.timestamp = pd.to_datetime(ratings.timestamp,\n",
    "                                   unit = \"s\")\n",
    "\n",
    "users = users.drop(columns=['zip_code'])  # Optional\n",
    "movies = movies.drop(columns=['title', 'release_date', 'video_release_date', 'IMDb_URL'])  # Keep genre booleans\n",
    "\n",
    "data = ratings.merge(users, on='user').merge(movies, on='item')\n",
    "\n",
    "# Create design matrix for regression model\n",
    "# Create categorical variables\n",
    "factor_vars = data[['gender', 'occupation']]\n",
    "factors = OneHotEncoder().fit_transform(factor_vars)\n",
    "\n",
    "age = data[['age']].values\n",
    "\n",
    "# get the genres\n",
    "genres = data[[col for col in data.columns if col.startswith('genre_')]].values\n",
    "\n",
    "user_enc = LabelEncoder().fit_transform(data['user'])\n",
    "item_enc = LabelEncoder().fit_transform(data['item'])\n",
    "\n",
    "# Use a sparse matrix for the design matrix\n",
    "X = scipy.sparse.hstack([\n",
    "    factors,\n",
    "    age,\n",
    "    genres,\n",
    "    user_enc.reshape(-1, 1),\n",
    "    item_enc.reshape(-1, 1)\n",
    "])\n",
    "\n",
    "y = data['rating'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b838a02f",
   "metadata": {},
   "source": [
    "## Pointwise recommender \n",
    "\n",
    "This pointwise ranking recommender uses linear regression with L2 regularization (i.e., ridge regression).  The linear model is fit using 80% of the data with movie genre, user age, gender, and occupation as covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d84ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of pointwise recommender\n",
      "Test RMSE: 1.0788\n",
      "Mean nDCG@10: 0.8830\n"
     ]
    }
   ],
   "source": [
    "from recommenders.evaluation.python_evaluation import ndcg_at_k\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import ndcg_score, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_full = data[['user', 'item', 'rating']].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test, train_data, test_data = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    data,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 1)\n",
    "\n",
    "# Create and fit the regression model\n",
    "ALPHA = 1.0\n",
    "regression_model = Ridge(alpha = ALPHA)\n",
    "regression_model.fit(X_train,\n",
    "                     y_train)\n",
    "\n",
    "regression_predictions = regression_model.predict(X_test)\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, regression_predictions)\n",
    "\n",
    "print(\"Results of pointwise recommender\")\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "#data_full = data[['user', 'item', 'rating']].copy()\n",
    "test_data['prediction'] = regression_predictions\n",
    "\n",
    "eval_ndcg = ndcg_at_k(test_data,\n",
    "                      test_data,\n",
    "                      col_user = 'user',\n",
    "                      col_item = 'item',\n",
    "                      col_rating = 'rating',\n",
    "                      col_prediction = 'prediction',\n",
    "                      score_type = \"raw\", # binary\n",
    "                      k = 10)\n",
    "\n",
    "print(f\"Mean nDCG@10: {eval_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d73b3f7",
   "metadata": {},
   "source": [
    "### Pairwise Using BPR\n",
    "\n",
    "In this second model, we rank based on the Bayesian Personalized Ranking algorithm which uses a pairwise method and that uses a maximum a posteriori estimate (Rendle et al 2009). The code below was informed by a Jupyter notebook associated with the `recommenders` Python package (“Bayesian Personalized Ranking (BPR)” 2023).\n",
    "\n",
    "References:\n",
    "* “Bayesian Personalized Ranking (BPR).” 2023. GitHub. December 21, 2023. https://github.com/recommenders-team/recommenders/blob/main/examples/02_model_collaborative_filtering/cornac_bpr_deep_dive.ipynb.\n",
    "\n",
    "* Rendle, Steﬀen, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. “BPR: Bayesian Personalized Ranking from Implicit Feedback.” Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bbae53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matthew\\nu_projects\\rec_systems\\.venv2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 200/200 [00:08<00:00, 23.01it/s, correct=97.48%, skipped=9.70%] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cornac.models.bpr.recom_bpr.BPR at 0x22ea3998450>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cornac\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.models.cornac.cornac_utils import predict_ranking\n",
    "\n",
    "K = 10\n",
    "train, test = python_random_split(ratings,\n",
    "                                  0.8)\n",
    "\n",
    "bpr_train_data = cornac.data.Dataset.from_uir(train.itertuples(index = False),\n",
    "                                              seed = 1)\n",
    "\n",
    "NUM_FACTORS = 200\n",
    "bpr = cornac.models.BPR(\n",
    "    k = NUM_FACTORS,\n",
    "    max_iter = 200,\n",
    "    learning_rate = 0.01,\n",
    "    lambda_reg = 0.001,\n",
    "    verbose = True,\n",
    "    seed = 1\n",
    ")\n",
    "\n",
    "bpr.fit(bpr_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faff06af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of pairwise (BPR) recommender\n",
      "RMSE: 2.0438\n",
      "Mean nDCG@10: 0.8846\n"
     ]
    }
   ],
   "source": [
    "all_predictions = predict_ranking(bpr,\n",
    "                                  train,\n",
    "                                  usercol = 'user',\n",
    "                                  itemcol = 'item',\n",
    "                                  remove_seen = True)\n",
    "\n",
    "bpr_eval_data = pd.merge(test,\n",
    "                     all_predictions,\n",
    "                     how = \"left\",\n",
    "                     on = [\"user\", \"item\"])\n",
    "\n",
    "bpr_eval_data = bpr_eval_data[~bpr_eval_data.prediction.isna()]\n",
    "\n",
    "k = 10\n",
    "eval_ndcg = ndcg_at_k(bpr_eval_data,\n",
    "                      bpr_eval_data,\n",
    "                      col_user = 'user',\n",
    "                      col_item = 'item',\n",
    "                      col_rating = 'rating',\n",
    "                      col_prediction = 'prediction',\n",
    "                      score_type = \"raw\",\n",
    "                      k = k)\n",
    "\n",
    "rmse = root_mean_squared_error(bpr_eval_data.rating,\n",
    "                               bpr_eval_data.prediction)\n",
    "\n",
    "print(\"Results of pairwise (BPR) recommender\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"Mean nDCG@10: {eval_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78c9d87",
   "metadata": {},
   "source": [
    "### Listwise Model\n",
    "\n",
    "This listwise model uses the `LightGBM` package and the LambdaRank algorithm (Burges et al 2007), and as a listwise model, the loss function considers the ordering of all items (not just pairs as with the pairwise model).\n",
    "\n",
    "Burges, Christopher J.C., Robert Ragno, and Quoc Viet Le. 2007. “Learning to Rank with Nonsmooth Cost Functions.” In Advances in Neural Information Processing Systems 19, edited by Bernhard Schölkopf, John Platt, and Thomas Hofmann, 193–200. The MIT Press. https://doi.org/10.7551/mitpress/7503.003.0029.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae0c0f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 628\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 23\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Encode the categorical features\n",
    "for col in [\"gender\", \"occupation\", \"user\", \"item\"]:\n",
    "    data[col] = LabelEncoder().fit_transform(data[col])\n",
    "\n",
    "feature_cols = [\"user\", \"item\", \"age\", \"gender\", \"occupation\"] + [f\"genre_{i}\" for i in range(19)]\n",
    "\n",
    "X = data[feature_cols]\n",
    "y = data[\"rating\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test, data_train, data_test = train_test_split(\n",
    "    X, y, data, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# Compute group sizes (items per user in training set)\n",
    "group_train = data_train.groupby(\"user\").size().values\n",
    "group_test = data_test.groupby(\"user\").size().values\n",
    "\n",
    "# Create datasets for lightgbm\n",
    "lgb_train_data = lgb.Dataset(X_train,\n",
    "                             label = y_train,\n",
    "                             group = group_train)\n",
    "lgb_test_data = lgb.Dataset(X_test,\n",
    "                            label = y_test, \n",
    "                            group = group_test)\n",
    "\n",
    "lgb_model_params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"ndcg_eval_at\": [5, 10],\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"min_data_in_leaf\": 20\n",
    "}\n",
    "\n",
    "lgb_model = lgb.train(lgb_model_params,\n",
    "                  lgb_train_data,\n",
    "                  valid_sets = [lgb_test_data],\n",
    "                  num_boost_round = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8380c2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of listwise recommender\n",
      "RMSE: 4.2005\n",
      "Mean nDCG@10: 0.9046\n"
     ]
    }
   ],
   "source": [
    "lgb_model.predict(X_test)\n",
    "\n",
    "eval_data = data_test.copy()\n",
    "eval_data[\"prediction\"] = lgb_model.predict(X_test)\n",
    "\n",
    "rmse = root_mean_squared_error(eval_data.rating,\n",
    "                               eval_data.prediction)\n",
    "\n",
    "eval_ndcg = ndcg_at_k(eval_data,\n",
    "                      eval_data,\n",
    "                      col_user = 'user',\n",
    "                      col_item = 'item',\n",
    "                      col_rating = 'rating',\n",
    "                      col_prediction = 'prediction',\n",
    "                      score_type = \"raw\", # binary\n",
    "                      k = 10)\n",
    "\n",
    "print(\"Results of listwise recommender\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"Mean nDCG@10: {eval_ndcg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
