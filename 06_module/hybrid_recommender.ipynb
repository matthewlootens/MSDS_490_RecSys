{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cab7654",
   "metadata": {},
   "source": [
    "## Hybrid Recommender\n",
    "\n",
    "A simple hybrid recommender that combines content-based recommenders that use embeddings from TF-IDF and a SVD-based collaborative-filtering algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb546930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "\n",
    "reviews = pd.read_json(\"data\\\\reviews_Musical_Instruments_5.json.zip\",\n",
    "                          lines=True)\n",
    "ratings = pd.read_csv(\"data\\\\ratings_Musical_Instruments.zip\", \n",
    "                      compression=\"zip\")\n",
    "\n",
    "reviews = reviews[[\"reviewerID\", \"asin\", \"reviewText\"]]\n",
    "reviews[\"reviewText\"] = reviews[\"reviewText\"].str.lower()\n",
    "\n",
    "data = pd.merge(reviews,\n",
    "                ratings,\n",
    "                left_on = [\"reviewerID\", \"asin\"],\n",
    "                right_on = [\"userId\", \"asin\"],\n",
    "                how=\"left\")\n",
    "\n",
    "mean_ratings = data.loc[:, [\"userId\", \"rating\"]].groupby(\"userId\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493125ca",
   "metadata": {},
   "source": [
    "### Create TF-IDF Embeddings for Content-Based Recommender\n",
    "\n",
    "I tried two different ways of creating the user profile: one way that took a sum of the embeddings and one that a mean-adjusted for each component of the feature vector.  The latter approach has better theoretical properties and performed better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13fb5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf = True, # tf is replaced with 1 + log(tf))\n",
    "                        stop_words = \"english\",\n",
    "                        max_features = 5000,\n",
    "                        max_df = 0.5,\n",
    "                        min_df = 5,\n",
    "                        token_pattern = u'(?ui)\\\\b\\\\w*[a-z]+\\\\w*\\\\b')\n",
    "\n",
    "tfidf_embeddings = tfidf.fit_transform(data[\"reviewText\"])\n",
    "\n",
    "item_profiles = {}\n",
    "for asin in data[\"asin\"].unique():\n",
    "    indices = data[data[\"asin\"] == asin].index\n",
    "    if len(indices) > 0:\n",
    "        item_profiles[asin] = tfidf_embeddings[indices].mean(axis=0)\n",
    "\n",
    "# User profile is simple sum of items above a threshold\n",
    "def get_user_profile(user_id, threshold = 3.5):\n",
    "    user_data = data[(data[\"reviewerID\"] == user_id) & (data[\"rating\"] >= threshold)]\n",
    "    user_profile = np.zeros((1, tfidf_embeddings.shape[1]))\n",
    "    for asin in user_data[\"asin\"]:\n",
    "        if asin in item_profiles:\n",
    "            user_profile += item_profiles[asin]\n",
    "    return user_profile\n",
    "\n",
    "# User profile is weighted averaged based on rating of items\n",
    "def get_user_profile_2(user, data, embeddings):\n",
    "    num_features = tfidf_embeddings.shape[1]\n",
    "    user_ratings = data[(data[\"reviewerID\"] == user_id)]\n",
    "\n",
    "    num_ratings = np.zeros(num_features)\n",
    "    csum_ratings = np.zeros(num_features)\n",
    "    \n",
    "    for i in range(len(user_ratings)):\n",
    "        userId = user_ratings.iloc[i,0]\n",
    "        asin = user_ratings.iloc[i,1]\n",
    "        embedding = item_profiles[asin]\n",
    "        \n",
    "        if embedding.shape[0] > 0:\n",
    "            mean_user_rating = mean_ratings[mean_ratings.index == userId].iloc[0,0]\n",
    "            rating = user_ratings.iloc[i, 4]\n",
    "            for j in embedding.nonzero()[1]:\n",
    "                num_ratings[j] += 1\n",
    "                csum_ratings[j] += mean_user_rating - rating\n",
    "   \n",
    "    # Calculate avg number of\n",
    "    user_profile = np.zeros(num_features)\n",
    "    for i in range(num_features):\n",
    "        if num_ratings[i] > 0:\n",
    "            user_profile[i] = csum_ratings[i] / num_ratings[i]\n",
    "    return user_profile.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ba133",
   "metadata": {},
   "source": [
    "### Create SVD Collaborative-Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2075173",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "svd_data = Dataset.load_from_df(data[[\"reviewerID\", \"asin\", \"rating\"]],\n",
    "                                     reader)\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "train_data, test_data = train_test_split(svd_data,\n",
    "                                     test_size = TEST_SIZE,\n",
    "                                     random_state = 1)\n",
    "svd = SVD(verbose = False)\n",
    "svd.fit(train_data)\n",
    "svd_preds = svd.test(test_data)\n",
    "\n",
    "svd_df = pd.DataFrame([(pred.uid,\n",
    "                        pred.iid,\n",
    "                        pred.est,\n",
    "                        pred.r_ui) for pred in svd_preds],\n",
    "                      columns = [\"user_id\", \"item_id\", \"svd_score\", \"true_rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef54c233",
   "metadata": {},
   "source": [
    "### Get Content-Based Recommedations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6510332",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_preds = []\n",
    "for user_id, item_id, _ in test_data:\n",
    "    if item_id in item_profiles:\n",
    "        user_profile = get_user_profile_2(user_id,\n",
    "                                          data,\n",
    "                                          item_profiles)\n",
    "        #user_profile = get_user_profile(user_id)\n",
    "        score = cosine_similarity(np.asarray(user_profile),\n",
    "                                  np.asarray(item_profiles[item_id])).flatten()[0]\n",
    "    else:\n",
    "        score = 0\n",
    "        \n",
    "    pred = (user_id, item_id, score)\n",
    "    content_preds.append(pred)\n",
    "\n",
    "# Take cosine-based recommnedations and convert to a ratings scale\n",
    "content = pd.DataFrame(content_preds,\n",
    "                          columns = [\"user_id\", \"item_id\", \"content_score\"])\n",
    "content[\"content_score\"] = MinMaxScaler(feature_range = (1, 5)).fit_transform(content[[\"content_score\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5225513",
   "metadata": {},
   "source": [
    "### Define helper functions\n",
    "#### Combine SVD and content-based recommendations using weighted sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817070e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybrid_recommendations(alpha):\n",
    "    hybrid = pd.merge(content,\n",
    "                        svd_df,\n",
    "                        on = [\"user_id\", \"item_id\"])\n",
    "    hybrid[\"hybrid_score\"] = (alpha * hybrid[\"svd_score\"] + \n",
    "                                (1 - alpha) * hybrid[\"content_score\"])\n",
    "    return hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd164a1c",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "Initial versions of these functions were generated from ChatGPT [OpenAI. 2025. ChatGPT (May 12 version) https://chat.openai.com/.]  I reviewed, debugged, and checked them for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "228edafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(ranked, relevant, k):\n",
    "    return len([i for i in ranked[:k] if i in relevant]) / k\n",
    "\n",
    "def recall_at_k(ranked, relevant, k):\n",
    "    if not relevant:\n",
    "        return 0\n",
    "    return len([i for i in ranked[:k] if i in relevant]) / len(relevant)\n",
    "\n",
    "def dcg_at_k(ranked, relevant, k):\n",
    "    n = np.min([k, len(ranked)])\n",
    "    return sum((1 if ranked[i] in relevant else 0) / np.log2(i + 2) for i in range(n))\n",
    "\n",
    "def idcg_at_k(relevant, k):\n",
    "    return sum(1 / np.log2(i + 2) for i in range(min(len(relevant), k)))\n",
    "\n",
    "def ndcg_at_k(ranked, relevant, k):\n",
    "    dcg = dcg_at_k(ranked, relevant, k)\n",
    "    idcg = idcg_at_k(relevant, k)\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def average_precision(ranked, relevant, k):\n",
    "    hits = 0\n",
    "    sum_precisions = 0\n",
    "    for i in range(min(len(ranked), k)):\n",
    "        if ranked[i] in relevant:\n",
    "            hits += 1\n",
    "            sum_precisions += hits / (i + 1)\n",
    "    return sum_precisions / min(len(relevant), k) if relevant else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf8d7c",
   "metadata": {},
   "source": [
    "### Find hybrid recommendations and associated metrics\n",
    "#### Equal weightings for SVD-based collaborative filtering and TF-IDF content-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1967d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rankings with 50.0% weighting for SVD-based\n",
      "collaborative-filtering recommendations:\n",
      "\n",
      "RMSE: 2.0868\n",
      "AUC: 0.1252\n",
      "Precision@10: 0.1630\n",
      "Recall@10: 0.9343\n",
      "nDCG@10: 0.8847\n",
      "MAP@10: 0.8671\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "THRESHOLD = 3.5\n",
    "recs_by_user = defaultdict(list)\n",
    "relevant_by_user = defaultdict(set)\n",
    "\n",
    "ALPHA = 0.5\n",
    "hybrid = get_hybrid_recommendations(ALPHA)\n",
    "\n",
    "for _, row in hybrid.iterrows():\n",
    "    user_id = row[\"user_id\"]\n",
    "    recs_by_user[user_id].append((row[\"item_id\"], row[\"hybrid_score\"]))\n",
    "    if row[\"true_rating\"] >= THRESHOLD:\n",
    "        relevant_by_user[user_id].add(row[\"item_id\"])\n",
    "\n",
    "rmse = mean_squared_error(hybrid[\"true_rating\"],\n",
    "                          hybrid[\"hybrid_score\"])\n",
    "\n",
    "binary_labels = (hybrid[\"true_rating\"] >= THRESHOLD).astype(int)\n",
    "\n",
    "auc = roc_auc_score(binary_labels,\n",
    "                    hybrid[\"hybrid_score\"])\n",
    "\n",
    "precisions, recalls, ndcgs, MAPs = [], [], [], []\n",
    "\n",
    "for user_id, recs in recs_by_user.items():\n",
    "    ranked = [item_id for item_id, _ in sorted(recs,\n",
    "                                               key = lambda x: x[1],\n",
    "                                               reverse = True)]\n",
    "    relevant = relevant_by_user[user_id]\n",
    "    precisions.append(precision_at_k(ranked, relevant, K))\n",
    "    recalls.append(recall_at_k(ranked, relevant, K))\n",
    "    ndcgs.append(ndcg_at_k(ranked, relevant, K))\n",
    "    MAPs.append(average_precision(ranked, relevant, K))\n",
    "\n",
    "print(f\"Rankings with {ALPHA * 100}% weighting for SVD-based\\ncollaborative-filtering recommendations:\\n\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"Precision@{K}: {np.mean(precisions):.4f}\")\n",
    "print(f\"Recall@{K}: {np.mean(recalls):.4f}\")\n",
    "print(f\"nDCG@{K}: {np.mean(ndcgs):.4f}\")\n",
    "print(f\"MAP@{K}: {np.mean(MAPs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e7ba9f",
   "metadata": {},
   "source": [
    "#### 80/20 weighting for SVD-based collaborative filtering (80%) and TF-IDF content-based (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5763acad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rankings with 80.0% weighting for SVD-based\n",
      "collaborative-filtering recommendations:\n",
      "\n",
      "RMSE: 1.1025\n",
      "AUC: 0.3862\n",
      "Precision@10: 0.1630\n",
      "Recall@10: 0.9343\n",
      "nDCG@10: 0.8944\n",
      "MAP@10: 0.8794\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "THRESHOLD = 3.5\n",
    "recs_by_user = defaultdict(list)\n",
    "relevant_by_user = defaultdict(set)\n",
    "\n",
    "ALPHA = 0.8\n",
    "hybrid = get_hybrid_recommendations(ALPHA)\n",
    "\n",
    "for _, row in hybrid.iterrows():\n",
    "    user_id = row[\"user_id\"]\n",
    "    recs_by_user[user_id].append((row[\"item_id\"], row[\"hybrid_score\"]))\n",
    "    if row[\"true_rating\"] >= THRESHOLD:\n",
    "        relevant_by_user[user_id].add(row[\"item_id\"])\n",
    "\n",
    "rmse = mean_squared_error(hybrid[\"true_rating\"],\n",
    "                          hybrid[\"hybrid_score\"])\n",
    "\n",
    "binary_labels = (hybrid[\"true_rating\"] >= THRESHOLD).astype(int)\n",
    "\n",
    "auc = roc_auc_score(binary_labels,\n",
    "                    hybrid[\"hybrid_score\"])\n",
    "\n",
    "precisions, recalls, ndcgs, MAPs = [], [], [], []\n",
    "\n",
    "for user_id, recs in recs_by_user.items():\n",
    "    ranked = [item_id for item_id, _ in sorted(recs,\n",
    "                                               key = lambda x: x[1],\n",
    "                                               reverse = True)]\n",
    "    relevant = relevant_by_user[user_id]\n",
    "    precisions.append(precision_at_k(ranked, relevant, K))\n",
    "    recalls.append(recall_at_k(ranked, relevant, K))\n",
    "    ndcgs.append(ndcg_at_k(ranked, relevant, K))\n",
    "    MAPs.append(average_precision(ranked, relevant, K))\n",
    "\n",
    "print(f\"Rankings with {ALPHA * 100}% weighting for SVD-based\\ncollaborative-filtering recommendations:\\n\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"Precision@{K}: {np.mean(precisions):.4f}\")\n",
    "print(f\"Recall@{K}: {np.mean(recalls):.4f}\")\n",
    "print(f\"nDCG@{K}: {np.mean(ndcgs):.4f}\")\n",
    "print(f\"MAP@{K}: {np.mean(MAPs):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
